import streamlit as st
import pandas as pd
from io import BytesIO



st.set_page_config(page_title="ë¸Œëœë“œ ìƒí’ˆ íë¦„ ëŒ€ì‹œë³´ë“œ", layout="wide")

# ----------------------------
# Google Sheets ì—°ë™
# ----------------------------
def get_gsheet_client(credentials_dict):
    if credentials_dict is None:
        return None
    import gspread
    from google.oauth2.service_account import Credentials
    # ìŠ¤í”„ë ˆë“œì‹œíŠ¸/ì›Œí¬ì‹œíŠ¸ë¥¼ "ìƒì„±"ê¹Œì§€ í•˜ë ¤ë©´ readonly ê¶Œí•œìœ¼ë¡œëŠ” ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
    # ì½ê¸°ë§Œ í•´ë„ ì•„ë˜ scopeëŠ” ë™ì‘í•˜ë©°, ìƒì„±/ì¶”ê°€ ì‹œíŠ¸ ë“±ë„ ì§€ì›í•©ë‹ˆë‹¤.
    scope = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive",
    ]
    creds = Credentials.from_service_account_info(
        credentials_dict, scopes=scope
    )
    return gspread.authorize(creds)


def _normalize_spreadsheet_id(spreadsheet_id_or_url):
    """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID ë˜ëŠ” URLì„ ë°›ì•„ IDë¡œ ì •ê·œí™”."""
    import re

    if spreadsheet_id_or_url is None:
        return ""
    s = str(spreadsheet_id_or_url).strip()
    if not s:
        return ""

    # URL: https://docs.google.com/spreadsheets/d/<ID>/edit...
    m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", s)
    if m:
        return m.group(1)

    # ê³µìœ  ë§í¬ì— key= ë¡œ ë“¤ì–´ì˜¤ëŠ” ì¼€ì´ìŠ¤
    m = re.search(r"(?:^|[?&])key=([a-zA-Z0-9-_]+)", s)
    if m:
        return m.group(1)

    return s


def open_or_create_spreadsheet(client, spreadsheet_id=None, spreadsheet_title=None, create_if_missing=False):
    """IDê°€ ìˆìœ¼ë©´ open_by_key, ì—†ìœ¼ë©´ titleë¡œ open(ì˜µì…˜ìœ¼ë¡œ create)."""
    import gspread

    sid = _normalize_spreadsheet_id(spreadsheet_id)
    if sid:
        return client.open_by_key(sid)

    title = (spreadsheet_title or "").strip() if spreadsheet_title else ""
    if not title:
        raise ValueError("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID/URL ë˜ëŠ” ì œëª©(spreadsheet_title)ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    try:
        return client.open(title)
    except gspread.exceptions.SpreadsheetNotFound:
        if not create_if_missing:
            raise
        return client.create(title)


def load_sheet_as_dataframe(
    client,
    spreadsheet_id=None,
    sheet_name=None,
    header_row=0,
    spreadsheet_title=None,
    create_spreadsheet_if_missing=False,
    create_worksheet_if_missing=False,
):
    """header_row: 0 = ì²« ë²ˆì§¸ í–‰ì´ í—¤ë”(ê¸°ë³¸), 1 = ë‘ ë²ˆì§¸ í–‰ì´ í—¤ë” ë“±"""
    try:
        spreadsheet = open_or_create_spreadsheet(
            client,
            spreadsheet_id=spreadsheet_id,
            spreadsheet_title=spreadsheet_title,
            create_if_missing=create_spreadsheet_if_missing,
        )

        # ì›Œí¬ì‹œíŠ¸ëŠ” ë°˜ë“œì‹œ "ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ì—° ë’¤"ì— ê°€ì ¸ì˜µë‹ˆë‹¤.
        if sheet_name and str(sheet_name).strip():
            try:
                worksheet = spreadsheet.worksheet(str(sheet_name).strip())
            except Exception as e:
                # ì—†ëŠ” ì›Œí¬ì‹œíŠ¸ë¥¼ ìš”ì²­í•œ ê²½ìš°(ì˜µì…˜) ìƒì„±
                if create_worksheet_if_missing:
                    worksheet = spreadsheet.add_worksheet(title=str(sheet_name).strip(), rows=1000, cols=26)
                else:
                    raise e
        else:
            worksheet = spreadsheet.sheet1

        rows = worksheet.get_all_values()
        if not rows or len(rows) <= header_row:
            return pd.DataFrame()
        # í—¤ë”Â·ì»¬ëŸ¼ëª… ì•ë’¤ ê³µë°± ì œê±°
        headers = [str(h).strip() for h in rows[header_row]]
        data_rows = rows[header_row + 1:]
        return pd.DataFrame(data_rows, columns=headers)
    except Exception as e:
        st.error(f"ì‹œíŠ¸ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

# ìŠ¤íƒ€ì¼ì½”ë“œ ì• 2ìë¦¬ â†’ ë¸Œëœë“œ í•œê¸€ëª…
BRAND_CODE_MAP = {
    "sp": "ìŠ¤íŒŒì˜¤",
    "rm": "ë¡œì— ",
    "mi": "ë¯¸ì˜",
    "wh": "í›„ì•„ìœ ",
    "nb": "ë‰´ë°œë€ìŠ¤",
    "eb": "ì—ë¸”ë¦°",
    "hp": "ìŠˆíœ",
    "cv": "í´ë¼ë¹„ìŠ¤",
    "nk": "ë‰´ë°œë€ìŠ¤í‚¤ì¦ˆ",
}

def brand_from_style_code(style_code):
    """ìŠ¤íƒ€ì¼ì½”ë“œ ì• 2ìë¦¬ë¡œ ë¸Œëœë“œëª… ë°˜í™˜ (ì†Œë¬¸ìë¡œ ë§¤í•‘)"""
    if pd.isna(style_code) or not str(style_code).strip():
        return ""
    code = str(style_code).strip()[:2].lower()
    return BRAND_CODE_MAP.get(code, code.upper())

# ì‹œíŠ¸ ì»¬ëŸ¼ëª… â†’ ì•± í•„ìˆ˜ ì»¬ëŸ¼ëª… ë§¤í•‘ (í•œê¸€/ë‹¤ë¥¸ í‘œê¸° ì§€ì›)
COLUMN_ALIASES = {
    "ë¸Œëœë“œ": "brand",
    "ì—°ë„ì‹œì¦Œ": "yearSeason",
    "ì—°ë„Â·ì‹œì¦Œ": "yearSeason",
    "ì—°ë„ ì‹œì¦Œ": "yearSeason",
    "ì‹œì¦Œ(Now)": "yearSeason",
    "ìŠ¤íƒ€ì¼ì½”ë“œ": "styleCode",
    "ìŠ¤íƒ€ì¼ ì½”ë“œ": "styleCode",
    "ìŠ¤íƒ€ì¼ì½”ë“œ(Now)": "styleCode",
    "ìƒí’ˆëª…": "productName",
    "ì»¬ëŸ¬ì½”ë“œ": "colorCode",
    "ìƒ‰ìƒì½”ë“œ": "colorCode",
    "ì»¬ëŸ¬ ì½”ë“œ": "colorCode",
    "ì»¬ëŸ¬ëª…": "colorName",
    "ìƒ‰ìƒ": "colorName",
    "ì»¬ëŸ¬ ëª…": "colorName",
    "ì¹¼ë¼(Now)": "colorName",
    "ì‚¬ì´ì¦ˆì½”ë“œ": "sizeCode",
    "ì‚¬ì´ì¦ˆ ì½”ë“œ": "sizeCode",
    "ì…ê³ ìˆ˜ëŸ‰": "inboundQty",
    "ì¶œê³ ìˆ˜ëŸ‰": "outboundQty",
    "ì¬ê³ ìˆ˜ëŸ‰": "stockQty",
    "íŒë§¤ìˆ˜ëŸ‰": "salesQty",
    "ëˆ„ì ì…ê³ ëŸ‰(ë¬¼ë¥˜+ì…ê³ ì¡°ì •+ë¸Œëœë“œê°„)": "inboundQty",
    "ì¶œê³ ëŸ‰[ì¶œê³ -ë°˜í’ˆ](ë§¤ì¥+ê³ ê°+ìƒ˜í”Œ+ë¸Œëœë“œê°„)": "outboundQty",
    "ëˆ„ì  íŒë§¤ëŸ‰": "salesQty",
    "íŒë§¤ì¬ê³ ëŸ‰(ì…ê³ ëŸ‰-ëˆ„íŒëŸ‰)": "stockQty",
    "ì´¬ì˜ì—¬ë¶€": "isShot",
    "is_shot": "isShot",
    "ë“±ë¡ì—¬ë¶€": "isRegistered",
    "is_registered": "isRegistered",
    "íŒë§¤ê°œì‹œì—¬ë¶€": "isOnSale",
    "is_on_sale": "isOnSale",
}

def ensure_year_season_from_columns(df):
    """ë…„ë„(Now) + ì‹œì¦Œ(Now) â†’ yearSeason ì¡°í•©"""
    if "yearSeason" in df.columns:
        return df
    if "ë…„ë„(Now)" in df.columns and "ì‹œì¦Œ(Now)" in df.columns:
        df = df.copy()
        df["yearSeason"] = df["ë…„ë„(Now)"].astype(str) + df["ì‹œì¦Œ(Now)"].astype(str)
    return df

def apply_column_aliases(df):
    """ì»¬ëŸ¼ëª… ì•ë’¤ ê³µë°± ì œê±° í›„ ì•Œë ¤ì§„ ë³„ì¹­ìœ¼ë¡œ ë§¤í•‘"""
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    df = ensure_year_season_from_columns(df)
    rename = {}
    for col in list(df.columns):
        if col in COLUMN_ALIASES:
            target = COLUMN_ALIASES[col]
            # ì´ë¯¸ ìˆëŠ” ì»¬ëŸ¼ìœ¼ë¡œ ë®ì–´ì“°ì§€ ì•ŠìŒ (ì˜ˆ: yearSeasonì€ ë…„ë„+ì‹œì¦Œìœ¼ë¡œ ì´ë¯¸ ì±„ì›€)
            if target not in df.columns or col == target:
                rename[col] = target
    return df.rename(columns=rename) if rename else df

def fill_missing_required_columns(df, required_columns):
    """ì—†ëŠ” í•„ìˆ˜ ì»¬ëŸ¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›€ (ì‹œíŠ¸ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ë•Œ ëŒ€ì‹œë³´ë“œë§Œ ë™ì‘í•˜ë„ë¡)"""
    df = df.copy()
    for col in required_columns:
        if col not in df.columns:
            if col in ("isShot", "isRegistered", "isOnSale"):
                df[col] = 0
            elif col in ("inboundQty", "outboundQty", "stockQty", "salesQty"):
                df[col] = 0
            else:
                df[col] = ""
    return df

# ----------------------------
# ìƒíƒœ íŒì • ë¡œì§
# ----------------------------
def get_verdict(inbound, outbound, is_shot, is_registered, is_on_sale):
    if inbound > 0 and outbound == 0:
        return "ì…ê³ "
    if outbound > 0 and is_shot == 0:
        return "ì¶œê³ "
    if is_shot == 1 and is_registered == 0:
        return "ì´¬ì˜"
    if is_registered == 1 and is_on_sale == 0:
        return "ë“±ë¡"
    if is_on_sale == 1:
        return "íŒë§¤ê°œì‹œ"
    return "ëŒ€ê¸°"

# ----------------------------
# ì´¬ì˜ ì™„ë£Œ íŒì •: ë¦¬í„°ì¹­ì™„ë£Œì¼ ë“± ë‚ ì§œ ì»¬ëŸ¼
# ----------------------------
# ê·œì¹™: ë¨¸ë¦¿ê¸€ "ë¦¬í„°ì¹­ì™„ë£Œì¼" ì—´ì— "2026-01-20" ê°™ì€ ë‚ ì§œ ê°’ì´ ë“¤ì–´ ìˆìœ¼ë©´ ê·¸ í–‰ì€ ì´¬ì˜ Oë¡œ í‘œì‹œ.

def _normalize_col_name(name):
    """ì»¬ëŸ¼ëª… ë¹„êµìš©: ì•ë’¤ ê³µë°±Â·ì œì–´ë¬¸ì ì œê±°, ê³µë°± í†µì¼."""
    if name is None or not isinstance(name, str):
        return ""
    s = str(name).strip()
    s = "".join(c for c in s if ord(c) >= 32 or c in "\t\n\r")  # ì œì–´ë¬¸ì ì œê±°
    return s.replace(" ", "").replace("\u3000", "")

def _find_photo_date_column(df, preferred_name=None):
    """ì´¬ì˜ ì™„ë£Œë¥¼ íŒì •í•  ë‚ ì§œ ì»¬ëŸ¼. ë¦¬í„°ì¹­ì™„ë£Œì¼ ìš°ì„ , ì—†ìœ¼ë©´ ì´¬ì˜ì¼ì/í¬í† ì´¬ì˜ì¼ ë“±."""
    # 0ìˆœìœ„: Secretsì— ì§€ì •ëœ ì»¬ëŸ¼ëª…ì´ ìˆìœ¼ë©´ ì •í™•íˆ ê·¸ ì»¬ëŸ¼ ì‚¬ìš©
    if preferred_name and str(preferred_name).strip():
        name = str(preferred_name).strip()
        for c in df.columns:
            if str(c).strip() == name:
                return c
        name_norm = _normalize_col_name(name)
        for c in df.columns:
            if _normalize_col_name(c) == name_norm:
                return c
    # 1ìˆœìœ„: ë¨¸ë¦¿ê¸€ "ë¦¬í„°ì¹­ì™„ë£Œì¼" ì •í™•íˆ (ê³µë°±/ì œì–´ë¬¸ìë§Œ ì •ê·œí™”)
    for c in df.columns:
        if _normalize_col_name(c) == "ë¦¬í„°ì¹­ì™„ë£Œì¼":
            return c
    # 2ìˆœìœ„: ë¦¬í„°ì¹­ ê´€ë ¨ (ë¦¬í„°ì¹­ì™„ë£Œì¼, ë¦¬í„°ì¹­ì¼, ë¦¬í„°ì¹­ ì¼ì ë“±)
    for c in df.columns:
        s = str(c).strip()
        s_nospace = _normalize_col_name(c)
        if "ë¦¬í„°ì¹­" in s_nospace or "retouch" in s.lower():
            return c
    # 3ìˆœìœ„: ì´¬ì˜ì¼ì, í¬í† ì´¬ì˜ì¼, ë³´ì •ì™„ë£Œì¼ ë“±
    for c in df.columns:
        s = str(c).strip()
        s_nospace = _normalize_col_name(c)
        s_lower = s.lower()
        if (
            "í¬í† ì´¬ì˜" in s_nospace
            or "ì´¬ì˜ì¼" in s_nospace
            or "ì´¬ì˜ì¼ì" in s_nospace
            or "ë³´ì •ì™„ë£Œ" in s_nospace
            or s in ("photoShotDate", "shotDate", "retouchDoneDate", "retouch_date", "ì´¬ì˜ì¼ì", "ì´¬ì˜ ì¼ì")
        ):
            return c
    # 4ìˆœìœ„: 'OOì™„ë£Œì¼' í˜•íƒœ ì¤‘ ë“±ë¡/íŒë§¤ ì œì™¸
    for c in df.columns:
        s_nospace = _normalize_col_name(c)
        if "ì™„ë£Œì¼" in s_nospace and "ë“±ë¡" not in s_nospace and "íŒë§¤" not in s_nospace:
            return c
    return None

def _parse_date_series(ser):
    """ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ íŒŒì‹± (ë¬¸ìì—´, Excel/êµ¬ê¸€ ì‹œíŠ¸ ì¼ë ¨ë²ˆí˜¸ ë“±). ê³µë°±/í˜•ì‹ ì°¨ì´ ê´€ëŒ€í•˜ê²Œ ì²˜ë¦¬."""
    out = pd.to_datetime(ser, errors="coerce")
    # íŒŒì‹± ì‹¤íŒ¨í•œ ì…€: ì•ë’¤ ê³µë°± ì œê±° í›„ ì¬ì‹œë„
    still_na = out.isna()
    if still_na.any():
        try:
            cleaned = ser.astype(str).str.strip()
            out2 = pd.to_datetime(cleaned, errors="coerce")
            out = out.fillna(out2)
        except Exception:
            pass
    # "2025. 1. 15"ì²˜ëŸ¼ ì  ì•ë’¤ ê³µë°± ì œê±° í›„ ì¬ì‹œë„
    still_na = out.isna()
    if still_na.any():
        try:
            s = ser.astype(str).str.strip()
            s = s.str.replace(r"\s*\.\s*", ".", regex=True).str.replace(r"\s*-\s*", "-", regex=True)
            out3 = pd.to_datetime(s, errors="coerce")
            out = out.fillna(out3)
        except Exception:
            pass
    # êµ¬ê¸€ ì‹œíŠ¸/ì—‘ì…€ ë‚ ì§œ ì¼ë ¨ë²ˆí˜¸(ë¬¸ìì—´ "45324" ë“±)
    if out.isna().any():
        numeric = pd.to_numeric(ser, errors="coerce")
        valid_num = numeric.notna() & (numeric > 10000) & (numeric < 1000000)
        if valid_num.any():
            fixed = pd.to_datetime(numeric[valid_num], unit="D", origin="1899-12-30")
            out = out.fillna(fixed)
    return out

def _looks_like_date_value(val):
    """ì…€ ê°’ì´ ë‚ ì§œì²˜ëŸ¼ ë³´ì´ë©´ True (íŒŒì‹± ì‹¤íŒ¨í•´ë„ 'ê°’ ìˆìŒ'ìœ¼ë¡œ ì´¬ì˜ ì™„ë£Œ ì²˜ë¦¬ìš©)."""
    if val is None or (isinstance(val, float) and pd.isna(val)):
        return False
    s = str(val).strip()
    if not s or s in ("-", ".", "ë¯¸ì •", "n/a", "N/A", "â€”"):
        return False
    # ìˆ«ì 4ìë¦¬ ì´ìƒ + êµ¬ë¶„ì(-./) ìˆìœ¼ë©´ ë‚ ì§œë¡œ ê°„ì£¼
    if any(sep in s for sep in ("-", ".", "/")) and any(c.isdigit() for c in s):
        return True
    # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°(ì—‘ì…€ ì‹œë¦¬ì–¼)
    if s.isdigit() and 10000 <= int(s) <= 1000000:
        return True
    return False


def compute_shot_done_series(df, preferred_date_column=None):
    """ì´¬ì˜ ì™„ë£Œ ì—¬ë¶€(0/1) ì‹œë¦¬ì¦ˆë¥¼ ìƒì„±.

    ë¦¬í„°ì¹­ì™„ë£Œì¼ì— ê°’(ë‚ ì§œ)ì´ ìˆìœ¼ë©´ ê·¸ í–‰ì€ ì´¬ì˜ ì™„ë£Œ(O).
    ë¦¬í„°ì¹­ì™„ë£Œì¼ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì´¬ì˜ì¼ì/í¬í† ì´¬ì˜ì¼ ë“± ë‹¤ë¥¸ ë‚ ì§œ ì»¬ëŸ¼, ì—†ìœ¼ë©´ isShot(0/1) í´ë°±.
    """
    date_col = _find_photo_date_column(df, preferred_name=preferred_date_column)
    if date_col is not None and date_col in df.columns:
        ser = _parse_date_series(df[date_col])
        done = ser.notna().astype(int)
        # íŒŒì‹±ì€ ì‹¤íŒ¨í–ˆì§€ë§Œ ê°’ì´ ë‚ ì§œ í˜•íƒœì¸ ê²½ìš°(ê³µë°±/í˜•ì‹ ì´ìŠˆ) O ì²˜ë¦¬
        if (done == 0).any():
            raw = df[date_col].astype(str).str.strip()
            fallback = raw.apply(_looks_like_date_value).astype(int)
            done = done.where(done == 1, fallback)
        return done

    if "isShot" in df.columns:
        return (pd.to_numeric(df["isShot"], errors="coerce").fillna(0).astype(int) == 1).astype(int)

    return pd.Series([0] * len(df), index=df.index, dtype="int64")

# ----------------------------
# ìŠ¤ëƒ…ìƒ· ì¦ê° ê³„ì‚°
# ----------------------------
def compute_flow_deltas(df):
    if len(df) < 2:
        return None
    this_week = df.iloc[0]
    last_week = df.iloc[1]
    return {
        "ì…ê³ ": this_week["inboundDone"] - last_week["inboundDone"],
        "ì¶œê³ ": this_week["outboundDone"] - last_week["outboundDone"],
        "ì´¬ì˜": this_week["shotDone"] - last_week["shotDone"],
        "ë“±ë¡": this_week["registeredDone"] - last_week["registeredDone"],
        "íŒë§¤ê°œì‹œ": this_week["onSaleDone"] - last_week["onSaleDone"],
    }

# ----------------------------
# ì œëª©
# ----------------------------
st.title("ë¸Œëœë“œ ìƒí’ˆ íë¦„ ëŒ€ì‹œë³´ë“œ")
st.caption("ì…ê³  Â· ì¶œê³  Â· ì´¬ì˜ Â· ë“±ë¡ Â· íŒë§¤ê°œì‹œ í˜„í™©")

# ----------------------------
# Google Sheets ì—°ê²° (Secretsë§Œ ì‚¬ìš©, UI ì—†ìŒ)
# ----------------------------
SPREADSHEET_OPTIONS = {
    "BASE_SPREADSHEET_ID": "BASE",
    "SP_SPREADSHEET_ID": "SP",
    "MI_SPREADSHEET_ID": "MI",
    "CV_SPREADSHEET_ID": "CV",
    "WH_SPREADSHEET_ID": "WH",
    "RM_SPREADSHEET_ID": "RM",
    "EB_SPREADSHEET_ID": "EB",
}

def get_spreadsheet_ids_from_secrets():
    ids = {}
    for secret_key, label in SPREADSHEET_OPTIONS.items():
        try:
            val = st.secrets.get(secret_key, "")
            if val and str(val).strip():
                ids[label] = str(val).strip()
        except Exception:
            pass
    return ids

creds_dict = None
try:
    if "gcp_service_account" in st.secrets:
        creds_dict = dict(st.secrets["gcp_service_account"])
    elif "google_service_account" in st.secrets:
        creds_dict = dict(st.secrets["google_service_account"])
except Exception:
    pass
gs_client = get_gsheet_client(creds_dict) if creds_dict else None

spreadsheet_ids = get_spreadsheet_ids_from_secrets()
spreadsheet_title = None
create_spreadsheet_if_missing = False

if not spreadsheet_ids:
    # IDê°€ ì—†ìœ¼ë©´(ì˜µì…˜) ì œëª©ìœ¼ë¡œ ì—´ê¸°/ìƒì„±í•  ìˆ˜ ìˆê²Œ ì§€ì›
    # - AUTO_CREATE_SPREADSHEET=true ì´ê³ 
    # - SPREADSHEET_TITLE(ë˜ëŠ” BASE_SPREADSHEET_TITLE)ê°€ ìˆìœ¼ë©´
    # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ìƒì„±/ì˜¤í”ˆ í›„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.
    auto_create = str(st.secrets.get("AUTO_CREATE_SPREADSHEET", "")).strip().lower() in ("1", "true", "yes", "y")
    spreadsheet_title = str(st.secrets.get("SPREADSHEET_TITLE", "")).strip() or str(st.secrets.get("BASE_SPREADSHEET_TITLE", "")).strip()
    if auto_create and spreadsheet_title:
        selected_label = "AUTO"
        spreadsheet_id = None
        create_spreadsheet_if_missing = True
    else:
        st.error("Secretsì— ìŠ¤í”„ë ˆë“œì‹œíŠ¸ IDê°€ ì—†ìŠµë‹ˆë‹¤. BASE_SPREADSHEET_ID ë“±ì„ ì„¤ì •í•˜ê±°ë‚˜, AUTO_CREATE_SPREADSHEET=true ì™€ SPREADSHEET_TITLEì„ ì„¤ì •í•˜ì„¸ìš”.")
        st.stop()
else:
    # ê¸°ë³¸ê°’: Secrets ì²« ë²ˆì§¸ ì‹œíŠ¸, ì²« ì‹œíŠ¸ íƒ­, í—¤ë” 1í–‰
    selected_label = list(spreadsheet_ids.keys())[0]
    spreadsheet_id = spreadsheet_ids[selected_label]
items_sheet_name = ""
header_row = 1
snapshots_sheet_name = ""

if not gs_client:
    st.info("Streamlit Secretsì— **gcp_service_account** ë˜ëŠ” **google_service_account**ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”.")
    st.stop()
items_df = load_sheet_as_dataframe(
    gs_client,
    spreadsheet_id,
    sheet_name=items_sheet_name if items_sheet_name.strip() else None,
    header_row=int(header_row) - 1,
    spreadsheet_title=spreadsheet_title,
    create_spreadsheet_if_missing=create_spreadsheet_if_missing,
)
if items_df is None:
    st.stop()
if len(items_df) == 0:
    st.warning("ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# í•œê¸€/ë‹¤ë¥¸ ì»¬ëŸ¼ëª…ì„ í•„ìˆ˜ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘
items_df = apply_column_aliases(items_df)

# ë¸Œëœë“œ: ìŠ¤íƒ€ì¼ì½”ë“œ(Now) ì• 2ìë¦¬ â†’ ë§¤í•‘ í…Œì´ë¸” í•œê¸€ëª…
if "styleCode" in items_df.columns:
    items_df["brand"] = items_df["styleCode"].apply(brand_from_style_code)

# ì‹œíŠ¸ì—ì„œ ì½ì€ ê°’ì€ ë¬¸ìì—´ì´ë¯€ë¡œ ìˆ«ì ì»¬ëŸ¼ ë³€í™˜
numeric_cols = [
    "inboundQty", "outboundQty", "stockQty", "salesQty",
    "isShot", "isRegistered", "isOnSale"
]
for col in numeric_cols:
    if col in items_df.columns:
        items_df[col] = pd.to_numeric(items_df[col], errors="coerce").fillna(0).astype(int)

required_columns = [
    "brand", "yearSeason", "styleCode", "productName",
    "colorCode", "colorName", "sizeCode",
    "inboundQty", "outboundQty", "stockQty", "salesQty",
    "isShot", "isRegistered", "isOnSale"
]

missing = [col for col in required_columns if col not in items_df.columns]
if missing:
    items_df = fill_missing_required_columns(items_df, required_columns)

# ----------------------------
# ì´¬ì˜ ì™„ë£Œ ì—¬ë¶€ ê³„ì‚° (__shot_done)
# - ë¦¬í„°ì¹­ì™„ë£Œì¼ ë“± ë‚ ì§œê°€ ìˆìœ¼ë©´ Oë¡œ í‘œì‹œ
# ----------------------------
# Secretsì— ì´¬ì˜ ë‚ ì§œ ì»¬ëŸ¼ëª… ì§€ì • ê°€ëŠ¥ (ì‹œíŠ¸ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ë•Œ)
preferred_shot_date_col = (st.secrets.get("SHOT_DATE_COLUMN") or "").strip() or None
items_df["__shot_done"] = compute_shot_done_series(items_df, preferred_date_column=preferred_shot_date_col)
shot_date_column = _find_photo_date_column(items_df, preferred_name=preferred_shot_date_col)  # í™”ë©´ì—ì„œ ì›ì¸ í™•ì¸ìš©

# ----------------------------
# verdict ìƒì„±
# ----------------------------
items_df["verdict"] = items_df.apply(
    lambda r: get_verdict(
        r["inboundQty"],
        r["outboundQty"],
        r["__shot_done"],
        r["isRegistered"],
        r["isOnSale"],
    ),
    axis=1,
)

# ì—°ë„ ì»¬ëŸ¼ (í•„í„°ìš©, yearSeason ì• 4ìë¦¬)
items_df["_year"] = items_df["yearSeason"].astype(str).str[:4]

# ----------------------------
# í•„í„° ì˜ì—­
# ----------------------------
col1, col2, col3, col4 = st.columns(4)
with col1:
    brand = st.selectbox("ë¸Œëœë“œ", sorted(items_df["brand"].unique()))
with col2:
    years = sorted(items_df["_year"].dropna().unique())
    year = st.selectbox("ì—°ë„", years, key="year") if years else None
with col3:
    season_options = sorted(
        items_df.loc[items_df["_year"] == year, "yearSeason"].unique()
    ) if year is not None else []
    year_seasons = st.multiselect(
        "ì‹œì¦Œ",
        season_options,
        default=season_options if season_options else [],
        key="season",
    )
with col4:
    search = st.text_input(
        "ìŠ¤íƒ€ì¼ì½”ë“œ ê²€ìƒ‰",
        placeholder="ìŠ¤íƒ€ì¼ì½”ë“œ ë˜ëŠ” íŒì • ìƒíƒœ ê²€ìƒ‰",
    )

if year is not None and year_seasons:
    filtered_df = items_df[
        (items_df["brand"] == brand)
        & (items_df["_year"] == year)
        & (items_df["yearSeason"].isin(year_seasons))
    ].copy()
else:
    filtered_df = items_df[(items_df["brand"] == brand)].copy()
    if year is not None:
        filtered_df = filtered_df[filtered_df["_year"] == year]
    if year_seasons:
        filtered_df = filtered_df[filtered_df["yearSeason"].isin(year_seasons)]

if search:
    filtered_df = filtered_df[
        filtered_df["styleCode"].astype(str).str.contains(search, case=False, na=False)
        | filtered_df["verdict"].str.contains(search, case=False, na=False)
    ]

# ë°œì£¼ ìŠ¤íƒ€ì¼ ìˆ˜(ê³ ìœ  styleCode), ì…ê³ /ì¶œê³  ë“±ì€ ìŠ¤íƒ€ì¼ ìˆ˜ë¡œ ì§‘ê³„
total_n = filtered_df["styleCode"].nunique()
if total_n == 0:
    st.info("ì„ íƒí•œ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ìŠ¤ëƒ…ìƒ· ì¦ê° (ì¹´ë“œì— í•¨ê»˜ í‘œì‹œìš©)
deltas = None
if snapshots_sheet_name and snapshots_sheet_name.strip():
    snapshots_df = load_sheet_as_dataframe(
        gs_client, spreadsheet_id, sheet_name=snapshots_sheet_name.strip()
    )
    if snapshots_df is not None and len(snapshots_df) >= 2:
        snap_cols = ["inboundDone", "outboundDone", "shotDone", "registeredDone", "onSaleDone"]
        for c in snap_cols:
            if c in snapshots_df.columns:
                snapshots_df[c] = pd.to_numeric(snapshots_df[c], errors="coerce").fillna(0).astype(int)
        deltas = compute_flow_deltas(snapshots_df)

# ----------------------------
# íë¦„ ì§‘ê³„ ì¹´ë“œ (ìŠ¤íƒ€ì¼ ìˆ˜ ê¸°ì¤€: í•´ë‹¹ ë‹¨ê³„ 1ê±´ì´ë¼ë„ ìˆìœ¼ë©´ ìŠ¤íƒ€ì¼ í¬í•¨)
# ----------------------------
flow_types = ["ì…ê³ ", "ì¶œê³ ", "ì´¬ì˜", "ë“±ë¡", "íŒë§¤ê°œì‹œ"]
# íë¦„ë³„ ì¡°ê±´: í•´ë‹¹ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” í–‰ì´ í•˜ë‚˜ë¼ë„ ìˆëŠ” ìŠ¤íƒ€ì¼ ìˆ˜
_flow_conditions = {
    "ì…ê³ ": (filtered_df["inboundQty"] > 0),
    "ì¶œê³ ": (filtered_df["outboundQty"] > 0),
    "ì´¬ì˜": (filtered_df["__shot_done"] == 1),
    "ë“±ë¡": (filtered_df["isRegistered"] == 1),
    "íŒë§¤ê°œì‹œ": (filtered_df["isOnSale"] == 1),
}
flow_counts = pd.Series({
    flow: filtered_df.loc[cond]["styleCode"].nunique()
    for flow, cond in _flow_conditions.items()
})

if "selected_flow" not in st.session_state:
    st.session_state.selected_flow = flow_types[0]

card_cols = st.columns(len(flow_types) + 1)
for i, flow in enumerate(flow_types):
    count = int(flow_counts.get(flow, 0))
    delta_val = deltas.get(flow, 0) if deltas else None
    delta_str = f"â–²{delta_val}" if (delta_val is not None and delta_val > 0) else (str(delta_val) if delta_val is not None else "")
    with card_cols[i]:
        btn_label = f"{flow}\n{count}/{total_n}"
        if delta_str:
            btn_label += f"  {delta_str}"
        if st.button(btn_label, key=f"flow_btn_{flow}", use_container_width=True):
            st.session_state.selected_flow = flow
        if st.session_state.selected_flow == flow:
            st.caption("âœ“ ì„ íƒë¨")

with card_cols[-1]:
    view_mode = st.radio(
        "ë³´ê¸° ë‹¨ìœ„",
        ["ìŠ¤íƒ€ì¼", "ë‹¨í’ˆ"],
        horizontal=True,
        label_visibility="collapsed",
        key="view_mode",
    )

selected_flow = st.session_state.selected_flow

flow_df = filtered_df.loc[_flow_conditions[selected_flow]].copy()

# ìŠ¤íƒ€ì¼ ë‹¨ìœ„: styleCode ê¸°ì¤€ ì§‘ê³„ (ìˆ˜ëŸ‰ í•©ì‚°, ì´¬ì˜/ë“±ë¡/íŒë§¤ê°œì‹œëŠ” í•˜ë‚˜ë¼ë„ 1ì´ë©´ 1)
if view_mode == "ìŠ¤íƒ€ì¼" and len(flow_df) > 0:
    group_cols = ["brand", "yearSeason", "styleCode"]
    agg_dict = {
        "inboundQty": "sum",
        "outboundQty": "sum",
        "stockQty": "sum",
        "salesQty": "sum",
        "isShot": "max",
        "__shot_done": "max",
        "isRegistered": "max",
        "isOnSale": "max",
    }
    if "productName" in flow_df.columns:
        agg_dict["productName"] = "first"
    if "colorName" in flow_df.columns:
        agg_dict["colorName"] = lambda s: " / ".join(s.dropna().astype(str).unique()[:5])
    flow_df = flow_df.groupby(group_cols, dropna=False).agg(agg_dict).reset_index()

flow_df["verdict"] = selected_flow

# í‘œì‹œìš© ì»¬ëŸ¼: ì´¬ì˜ O/X, ë“±ë¡ O/X, íŒë§¤ ìƒíƒœ
flow_df["_ì´¬ì˜"] = flow_df["__shot_done"].map(lambda x: "O" if int(x) == 1 else "X")
flow_df["_ë“±ë¡"] = flow_df["isRegistered"].map(lambda x: "O" if x == 1 else "X")
flow_df["_íŒë§¤"] = flow_df.apply(
    lambda r: "íŒë§¤ê°œì‹œ" if r["isOnSale"] == 1 else ("ì¶œê³ ì „" if r["outboundQty"] == 0 else "ì¶œê³ "),
    axis=1,
)

# ----------------------------
# ìƒì„¸ í…Œì´ë¸” (NO, ìŠ¤íƒ€ì¼ì½”ë“œ, ìƒí’ˆëª…, ì»¬ëŸ¬, ì…ê³ /ì¶œê³ /ì¬ê³ /íŒë§¤ëŸ‰, ì´¬ì˜, ë“±ë¡, íŒë§¤)
# ----------------------------
st.subheader(f"ìƒì„¸ í˜„í™© Â· {selected_flow}")

display_df = flow_df.copy()
display_df.insert(0, "NO", range(1, len(display_df) + 1))
show_cols = ["NO", "styleCode", "productName", "colorName", "inboundQty", "outboundQty", "stockQty", "salesQty", "_ì´¬ì˜", "_ë“±ë¡", "_íŒë§¤"]
show_cols = [c for c in show_cols if c in display_df.columns]
display_df = display_df[show_cols]
display_df = display_df.rename(columns={
    "styleCode": "ìŠ¤íƒ€ì¼ì½”ë“œ",
    "productName": "ìƒí’ˆëª…",
    "colorName": "ì»¬ëŸ¬",
    "inboundQty": "ì…ê³ ëŸ‰",
    "outboundQty": "ì¶œê³ ëŸ‰",
    "stockQty": "ì¬ê³ ëŸ‰",
    "salesQty": "íŒë§¤ëŸ‰",
    "_ì´¬ì˜": "ì´¬ì˜",
    "_ë“±ë¡": "ë“±ë¡",
    "_íŒë§¤": "íŒë§¤",
})

st.dataframe(display_df, use_container_width=True, hide_index=True)

def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name="ìƒì„¸í˜„í™©")
    return output.getvalue()

excel_data = to_excel(display_df)
st.download_button(
    label="Download",
    data=excel_data,
    file_name=f"ìƒì„¸í˜„í™©_{selected_flow}.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)

# ----------------------------
# ì´¬ì˜ O/X ì›ì¸ í™•ì¸ (ë””ë²„ê·¸)
# ----------------------------
with st.expander("ğŸ” ì´¬ì˜ ì—´ì´ Xë¡œ ë‚˜ì˜¤ëŠ” ì´ìœ  í™•ì¸"):
    st.caption("íŠ¹ì • ìŠ¤íƒ€ì¼ì½”ë“œê°€ ì´¬ì˜ Oê°€ ì•„ë‹ˆë¼ Xë¡œ ë‚˜ì˜¬ ë•Œ, ì–´ë–¤ ì»¬ëŸ¼Â·ê°’ìœ¼ë¡œ íŒì •í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.")
    debug_style = st.text_input("ìŠ¤íƒ€ì¼ì½”ë“œ", value="SPABGA9A51", key="debug_style")
    if shot_date_column:
        st.write(f"**ì´¬ì˜ íŒì •ì— ì‚¬ìš© ì¤‘ì¸ ì»¬ëŸ¼:** `{shot_date_column}` (ì—¬ê¸°ì— ìœ íš¨í•œ ë‚ ì§œê°€ ìˆìœ¼ë©´ O)")
    else:
        st.write("**ì´¬ì˜ íŒì •ì— ì‚¬ìš© ì¤‘ì¸ ì»¬ëŸ¼:** ì—†ìŒ â†’ `isShot`(ì´¬ì˜ì—¬ë¶€) ê°’ìœ¼ë¡œ íŒì • ì¤‘.")
        st.caption("ì‹œíŠ¸ì—ì„œ ì½ì€ ì»¬ëŸ¼ ì´ë¦„ ì¤‘ì— ì´¬ì˜/ë¦¬í„°ì¹­ ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆì–´ì•¼ Oë¡œ í‘œì‹œë©ë‹ˆë‹¤. ì•„ë˜ ëª©ë¡ì—ì„œ í•´ë‹¹ ì»¬ëŸ¼ ì´ë¦„ì„ í™•ì¸í•œ ë’¤, Streamlit Secretsì— **SHOT_DATE_COLUMN** = ê·¸ ì´ë¦„(ë”°ì˜´í‘œ í¬í•¨)ìœ¼ë¡œ ë„£ìœ¼ë©´ í•´ë‹¹ ì»¬ëŸ¼ìœ¼ë¡œ ì´¬ì˜ O/Xë¥¼ íŒì •í•©ë‹ˆë‹¤.")
        all_cols = list(items_df.columns)
        # ì´¬ì˜/ë‚ ì§œì™€ ì—°ê´€ë  ìˆ˜ ìˆëŠ” ì´ë¦„ë§Œ ê°•ì¡°í•´ì„œ ë³´ì—¬ì£¼ê¸°
        date_like = [c for c in all_cols if any(k in str(c) for k in ("ì´¬ì˜", "ë¦¬í„°ì¹­", "ë³´ì •", "ì™„ë£Œ", "ì¼ì", "ë‚ ì§œ", "date", "shot", "retouch"))]
        if date_like:
            st.write("ì—°ê´€ ì»¬ëŸ¼ í›„ë³´:", ", ".join(f"`{c}`" for c in date_like))
        st.write("ì „ì²´ ì»¬ëŸ¼:", ", ".join(f"`{c}`" for c in all_cols[:30]) + (" â€¦" if len(all_cols) > 30 else ""))
    if debug_style and "styleCode" in items_df.columns:
        rows = items_df[items_df["styleCode"].astype(str).str.strip() == str(debug_style).strip()]
        if len(rows) == 0:
            st.warning(f"ìŠ¤íƒ€ì¼ì½”ë“œ '{debug_style}'ì— í•´ë‹¹í•˜ëŠ” í–‰ì´ ì—†ìŠµë‹ˆë‹¤. (í•„í„° ì¡°ê±´ì´ë‚˜ ì‹œíŠ¸ ë°ì´í„° í™•ì¸)")
        else:
            cols_show = ["styleCode", "__shot_done"]
            if shot_date_column and shot_date_column in items_df.columns:
                cols_show.insert(1, shot_date_column)
            cols_show = [c for c in cols_show if c in rows.columns]
            debug_df = rows[cols_show].copy()
            debug_df["ì´¬ì˜ í‘œì‹œ"] = debug_df["__shot_done"].map(lambda x: "O" if int(x) == 1 else "X")
            st.dataframe(debug_df, use_container_width=True, hide_index=True)
            st.caption("ìœ„ í‘œì—ì„œ **ì´¬ì˜ í‘œì‹œê°€ X**ì¸ ì´ìœ : í•´ë‹¹ í–‰ì˜ ë‚ ì§œ ì»¬ëŸ¼ ê°’ì´ ë¹„ì–´ ìˆê±°ë‚˜, ë‚ ì§œë¡œ ì¸ì‹ë˜ì§€ ì•Šì•˜ê±°ë‚˜, 'ë‚ ì§œì²˜ëŸ¼ ë³´ì´ëŠ” ê°’' ì¡°ê±´ì— ë§ì§€ ì•ŠìŒ.")
